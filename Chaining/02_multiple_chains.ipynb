{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97a7389c",
   "metadata": {},
   "source": [
    "#### Load Langsmith key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc0ddac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4be1d9",
   "metadata": {},
   "source": [
    "#### Set up local LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50e83db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "local_llm = ChatOllama(base_url=\"http://localhost:11434\",\n",
    "                       model=\"qwen2.5:latest\",\n",
    "                       temperature=0.5,\n",
    "                       max_tokens=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d2901d",
   "metadata": {},
   "source": [
    "#### Set up Chat Prompt Template for Details Response Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9798d345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "system_message_template = SystemMessagePromptTemplate.from_template(\"You are an expert in LLM\")\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(\"What is the advantage of using LLM on {env}\")\n",
    "chat_prompt_template = ChatPromptTemplate([system_message_template, human_message_template])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d978244",
   "metadata": {},
   "source": [
    "#### Set up Chat Prompt Template for Summarization Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b3cbca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "                                                                 Analyse the response and get me the heading from the {response}\n",
    "                                                                 Response should be in bullet points\n",
    "                                                                 \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e8efa5",
   "metadata": {},
   "source": [
    "#### Create Response and Summarization Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b00be55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Privacy and Security**\n",
      "- **Control Over Data**\n",
      "- **Low Latency**\n",
      "- **Cost-Effectiveness**\n",
      "- **Offline Capabilities**\n",
      "- **Customization and Fine-Tuning**\n",
      "- **Regulatory Compliance**\n",
      "- **Performance Optimization**\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "detailed_response_chain = chat_prompt_template | local_llm | StrOutputParser()\n",
    "summarization_chain_input = {\"response\": detailed_response_chain} | summarization_prompt_template\n",
    "summarization_chain = summarization_chain_input | local_llm | StrOutputParser()\n",
    "response = summarization_chain.invoke({\"env\": \"Local Machine\"})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
